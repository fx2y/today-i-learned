- [Cloud Native Go](https://www.oreilly.com/library/view/cloud-native-go/9781492076322/) teaches us best practices for adopting Go to solve cloud native management and deployment problems. It also teaches us how to compose and construct cloud native applications, from lower-level features to mid-level design patterns to high-level architectural considerations
	- Cloud Native Patterns introduces stability and concurrency patterns. On top of that, we learn by example about how to build a cloud native service
	- On the road of Go mastery, I personally also go with [Build an Orchestrator in Go](https://livebook.manning.com/book/build-an-orchestration-system-from-scratch/chapter-1/v-4/) and [100 Go Mistakes](https://livebook.manning.com/book/100-go-mistakes-how-to-avoid-them/chapter-1/v-10/). Additional two books from Manning are `Effective Go` and `Efficient Go`
- Go standard library are reference implementation and aren't optimized for performance. There're list of my personal preferred library for building a service
	- [Go Fiber](https://gofiber.io) . Go web framework built on top of Fasthttp.
	- [SQLBoiler](https://github.com/volatiletech/sqlboiler) for lightweight Go ORM or [sqlc](https://sqlc.dev/) if you don't need an expressive ORM on your applications. It's used if the query is relatively static and can be defined purely by SQL
	- [Sonic](https://github.com/bytedance/sonic) as faster JSON serializing & deserializing library
	- [zap](https://github.com/uber-go/zap) as faster logging in Go
	- Outside of OLTP database, there're potentially another integration depending on use case. For Kafka-compatible client, I prefer [franz-go](https://github.com/twmb/franz-go). For OLAP database, I prefer [ClickHouse](https://github.com/vahid-sohrabloo/chconn). (TODO: Faster redis-compatible client)
- Idea for personal Golang project
	- Utilizes io_uring and template for faster SSR. My personal preferred backend to frontend architecture is SSR with `htmx` for additional rich interaction on the client-side
	- Proactor pattern implementation with io_uring. Experimental work based on [nuclei](https://docs.rs/nuclei/latest/nuclei/) (Rust), but in Golang
	- Double-entry accounting SaaS with built-in analytics and fraud detection created in Golang + htmx
- Vector databases would be essential for vector query and indexing. AFAIK, we can use it to store features. Milvus and Weaviate would be my go to OSS project. Although Pinecone would provides more information as learning resources
- In that case, although I personally don't prefer to develop any service with Python, model serving would be better done through Python service. In order to improve performances, it's better to leverage FastAPI based on Starletter. Or, probably need comparison with plain aiohttp
- Experiment with Spring Cloud Stream - Kafka Binder with Redpanda as part day to day job
- Be careful on Reactor `onErrorContinue` because it might make database transaction not rollbacked
---
* Netty use non heap memory. So, be careful playing at edge of the sword
* Model serving. How to serve machine learning models? In general, Python is used for training purposes. But, serving the model isn't necessary using Python. We can export the model into standard format, like ONNX, and it can be served by Go/Java/etc programs
	* Can we serve it using vector search database? Vespa / Weaviate / etc
	* Another references: https://github.com/neuml/txtai/
	* Example, Kubernetes + SSD optimizations for fast embedding retrieval. Demux architecture to custom-batch every requests that fan out for inference. Go API to run the models. Flatbuffers is used to spend no cost in serialization. Turn every user request into batch that return back as a single request in ~1s.
	* Models act as building blocks for APIs + embeddings. Need to quickly retrieve all of unstructured document. How? Deep retrieval (through vector db probably)
	* Inference feedback loop? Using metric? Active/passive feedback mechanisms. Thumbs up/down for active and contextual analysis for passive (did good things happen after AI use). Inform how to better train the model. Ad-hoc/user-specific mechanisms to change results in real-time based on current context collected
* How to do adaptive batching in Go?
	* Reference: Clipper or any other model inference engine
* Good resources to diagnose [performance problem](https://pawelurbanek.com/postgresql-fix-performance) of PostgreSQL database
	* [Node PG Extras](https://github.com/pawurb/node-postgres-extras) 